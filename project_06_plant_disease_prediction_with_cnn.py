# -*- coding: utf-8 -*-
"""Project_06_Plant_Disease_Prediction_With_Cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tPPK0_CmfdPGWST3yUhRUBOLfHLFfDG2
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d abdallahalidev/plantvillage-dataset

import os

import zipfile
zip_ref = zipfile.ZipFile('/content/plantvillage-dataset.zip')
zip_ref.extractall('/content')
zip_ref.close()

os.listdir("/content/plantvillage dataset")

print("color len: ",len(os.listdir("/content/plantvillage dataset/color")))
print("color: ",os.listdir("/content/plantvillage dataset/color")[:5])

print("grayscale len: ",len(os.listdir("/content/plantvillage dataset/grayscale")))
print("grayscale: ",os.listdir("/content/plantvillage dataset/grayscale")[:5])

print("segmented len: ",len(os.listdir("/content/plantvillage dataset/segmented")))
print("segmented: ",os.listdir("/content/plantvillage dataset/segmented")[:5])

print(len(os.listdir("plantvillage dataset/color/Grape___healthy")))
print(os.listdir("plantvillage dataset/color/Grape___healthy")[:5])

# Data preprocessig
# database path
base_dir = "/content/plantvillage dataset/color"

import matplotlib.image as mping

image_path = "/content/plantvillage dataset/color/Apple___Apple_scab/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG"

img = mping.imread(image_path)
print(img.shape)
plt.imshow(img)
plt.axis('off')
plt.show()

image_path = "/content/plantvillage dataset/grayscale/Apple___Apple_scab/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG"
img = mping.imread(image_path)
print(img.shape)
plt.imshow(img)
plt.axis('off')
plt.show()

img_path = "/content/plantvillage dataset/segmented/Apple___Apple_scab/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335_final_masked.jpg"

img = mping.imread(img_path)
print(img.shape)
plt.imshow(img)
plt.axis('off')
plt.show()

print(img)

img.shape

# Image generator
from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size=32

image_gen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Train generator
train_ds = image_gen.flow_from_directory(
    base_dir,
    target_size=(256,256),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

# Train generator
validation_ds = image_gen.flow_from_directory(
    base_dir,
    target_size=(256,256),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,Input,Flatten,Dropout,BatchNormalization

model = Sequential()

model.add(Input(shape=(256,256,3)))

model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))

model.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))

model.add(Flatten())

model.add(Dense(128,activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(64,activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(train_ds.num_classes,activation='softmax'))

train_ds.num_classes

model.summary()

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds,validation_data=validation_ds,epochs=5,batch_size=batch_size)

# Evaluating
print("Evaluating model...")
val_loss, val_accuracy = model.evaluate(validation_ds, batch_size=batch_size)
print("Validation loss:", val_loss)
print("Validation accuracy:", val_accuracy)

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""# Building a Predictive System"""

# Function to Load and Preprocess the Image using Pillow
def load_and_preprocess_image(image_path, target_size=(256, 256)):
    # Load the image
    img = Image.open(image_path)
    # Resize the image
    img = img.resize(target_size)
    # Convert the image to a numpy array
    img_array = np.array(img)
    # Add batch dimension
    img_array = np.expand_dims(img_array, axis=0)
    # Scale the image values to [0, 1]
    img_array = img_array.astype('float32') / 255.
    return img_array

# Function to Predict the Class of an Image
def predict_image_class(model, image_path, class_indices):
    preprocessed_img = load_and_preprocess_image(image_path)
    predictions = model.predict(preprocessed_img)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    predicted_class_name = class_indices[predicted_class_index]
    return predicted_class_name

# Create a mapping from class indices to class names
class_indices = {value: key for key, value in train_ds.class_indices.items()}

train_ds.class_indices.items()

class_indices

# saving the class names as json file
import json
json.dump(class_indices, open('class_indices.json', 'w'))

from PIL import Image
import numpy as np

# Example Usage
# image_path = '/content/test_apple_black_rot.JPG'
image_path = '/content/test_blueberry_healthy.jpg'
#image_path = '/content/test_potato_early_blight.jpg'
predicted_class_name = predict_image_class(model, image_path, class_indices)

# Output the result
print("Predicted Class Name:", predicted_class_name)

"""# Save the model to Google drive or local"""

model.save('drive/MyDrive/plant_disease_prediction_model.h5')

model.save('plant_disease_prediction_model.h5')